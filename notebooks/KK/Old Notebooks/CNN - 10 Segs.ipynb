{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.keras import regularizers\n",
    "\n",
    "data_path = '../audio_data_MFCC/10_segs_per_track_output.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data (dataset_path, data1 = 'mfcc', data2 = 'labels'):\n",
    "    \n",
    "    np_file = np.load(dataset_path)\n",
    "    \n",
    "    return np_file[data1], np_file[data2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(data_path, test_size, validation_size):\n",
    "    \n",
    "    # load data\n",
    "    X, y = load_data(data_path, 'mfcc', 'labels')\n",
    "    \n",
    "    # create train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    \n",
    "    # create train/validation split\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, \n",
    "                                                                    y_train, \n",
    "                                                                    test_size=validation_size)\n",
    "    \n",
    "    \n",
    "    X_train = X_train[..., np.newaxis] # 4d array -> (num_samples, 130, 13, 1)\n",
    "    X_validation = X_validation[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "    \n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets('../audio_data_MFCC/6_segs_per_track_output.npz', 0.25, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # 1st conv layer\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(16, (1, 1), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # flatten output and feed it into dense layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3595, 216, 13, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Compile The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build CNN model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "model = build_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.00015)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in an early stop to avoid overtraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='accuracy', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "57/57 [==============================] - 24s 358ms/step - loss: 3.7112 - accuracy: 0.0960 - val_loss: 3.1894 - val_accuracy: 0.0923\n",
      "Epoch 2/150\n",
      "57/57 [==============================] - 16s 289ms/step - loss: 3.3490 - accuracy: 0.1230 - val_loss: 2.9640 - val_accuracy: 0.1935\n",
      "Epoch 3/150\n",
      "57/57 [==============================] - 16s 288ms/step - loss: 3.1837 - accuracy: 0.1622 - val_loss: 2.8841 - val_accuracy: 0.2136\n",
      "Epoch 4/150\n",
      "57/57 [==============================] - 17s 294ms/step - loss: 3.0155 - accuracy: 0.2097 - val_loss: 2.8206 - val_accuracy: 0.2747\n",
      "Epoch 5/150\n",
      "57/57 [==============================] - 17s 291ms/step - loss: 2.9349 - accuracy: 0.2149 - val_loss: 2.7620 - val_accuracy: 0.3070\n",
      "Epoch 6/150\n",
      "57/57 [==============================] - 17s 295ms/step - loss: 2.8195 - accuracy: 0.2576 - val_loss: 2.6868 - val_accuracy: 0.3359\n",
      "Epoch 7/150\n",
      "57/57 [==============================] - 17s 291ms/step - loss: 2.6962 - accuracy: 0.2868 - val_loss: 2.5993 - val_accuracy: 0.3548\n",
      "Epoch 8/150\n",
      "57/57 [==============================] - 19s 341ms/step - loss: 2.6257 - accuracy: 0.3092 - val_loss: 2.4856 - val_accuracy: 0.3993\n",
      "Epoch 9/150\n",
      "57/57 [==============================] - 23s 408ms/step - loss: 2.5597 - accuracy: 0.3248 - val_loss: 2.4063 - val_accuracy: 0.4105\n",
      "Epoch 10/150\n",
      "57/57 [==============================] - 20s 343ms/step - loss: 2.5031 - accuracy: 0.3412 - val_loss: 2.3383 - val_accuracy: 0.4294\n",
      "Epoch 11/150\n",
      "57/57 [==============================] - 18s 311ms/step - loss: 2.4264 - accuracy: 0.3651 - val_loss: 2.2758 - val_accuracy: 0.4572\n",
      "Epoch 12/150\n",
      "57/57 [==============================] - 20s 343ms/step - loss: 2.3513 - accuracy: 0.3767 - val_loss: 2.1880 - val_accuracy: 0.4750\n",
      "Epoch 13/150\n",
      "57/57 [==============================] - 20s 354ms/step - loss: 2.3147 - accuracy: 0.3889 - val_loss: 2.1860 - val_accuracy: 0.4561\n",
      "Epoch 14/150\n",
      "57/57 [==============================] - 17s 306ms/step - loss: 2.2539 - accuracy: 0.4045 - val_loss: 2.0779 - val_accuracy: 0.4894\n",
      "Epoch 15/150\n",
      "57/57 [==============================] - 19s 335ms/step - loss: 2.2259 - accuracy: 0.4033 - val_loss: 2.0246 - val_accuracy: 0.5083\n",
      "Epoch 16/150\n",
      "57/57 [==============================] - 17s 306ms/step - loss: 2.1688 - accuracy: 0.4295 - val_loss: 2.0565 - val_accuracy: 0.4549\n",
      "Epoch 17/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 2.1054 - accuracy: 0.4525 - val_loss: 1.9300 - val_accuracy: 0.5195\n",
      "Epoch 18/150\n",
      "57/57 [==============================] - 17s 296ms/step - loss: 2.0560 - accuracy: 0.4612 - val_loss: 1.9180 - val_accuracy: 0.5228\n",
      "Epoch 19/150\n",
      "57/57 [==============================] - 19s 339ms/step - loss: 1.9960 - accuracy: 0.4850 - val_loss: 1.8189 - val_accuracy: 0.5562\n",
      "Epoch 20/150\n",
      "57/57 [==============================] - 18s 317ms/step - loss: 2.0058 - accuracy: 0.4647 - val_loss: 1.8229 - val_accuracy: 0.5562\n",
      "Epoch 21/150\n",
      "57/57 [==============================] - 17s 304ms/step - loss: 1.9477 - accuracy: 0.4781 - val_loss: 1.8066 - val_accuracy: 0.5573\n",
      "Epoch 22/150\n",
      "57/57 [==============================] - 17s 299ms/step - loss: 1.9194 - accuracy: 0.5107 - val_loss: 1.8420 - val_accuracy: 0.5095\n",
      "Epoch 23/150\n",
      "57/57 [==============================] - 17s 298ms/step - loss: 1.8953 - accuracy: 0.5032 - val_loss: 1.8182 - val_accuracy: 0.5228\n",
      "Epoch 24/150\n",
      "57/57 [==============================] - 17s 294ms/step - loss: 1.8304 - accuracy: 0.5347 - val_loss: 1.7592 - val_accuracy: 0.5584\n",
      "Epoch 25/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 1.8591 - accuracy: 0.5103 - val_loss: 1.7319 - val_accuracy: 0.5506\n",
      "Epoch 26/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 1.8382 - accuracy: 0.5351 - val_loss: 1.6629 - val_accuracy: 0.5829\n",
      "Epoch 27/150\n",
      "57/57 [==============================] - 17s 291ms/step - loss: 1.7540 - accuracy: 0.5563 - val_loss: 1.7701 - val_accuracy: 0.4861\n",
      "Epoch 28/150\n",
      "57/57 [==============================] - 16s 285ms/step - loss: 1.7897 - accuracy: 0.5404 - val_loss: 1.6599 - val_accuracy: 0.5551\n",
      "Epoch 29/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 1.7240 - accuracy: 0.5489 - val_loss: 1.7817 - val_accuracy: 0.4950\n",
      "Epoch 30/150\n",
      "57/57 [==============================] - 16s 286ms/step - loss: 1.7035 - accuracy: 0.5561 - val_loss: 1.7532 - val_accuracy: 0.4816\n",
      "Epoch 31/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 1.7077 - accuracy: 0.5613 - val_loss: 1.6194 - val_accuracy: 0.5595\n",
      "Epoch 32/150\n",
      "57/57 [==============================] - 17s 292ms/step - loss: 1.6789 - accuracy: 0.5599 - val_loss: 1.6938 - val_accuracy: 0.5239\n",
      "Epoch 33/150\n",
      "57/57 [==============================] - 17s 294ms/step - loss: 1.6502 - accuracy: 0.5704 - val_loss: 1.6017 - val_accuracy: 0.5573\n",
      "Epoch 34/150\n",
      "57/57 [==============================] - 16s 289ms/step - loss: 1.6134 - accuracy: 0.5818 - val_loss: 1.5860 - val_accuracy: 0.5640\n",
      "Epoch 35/150\n",
      "57/57 [==============================] - 16s 289ms/step - loss: 1.6147 - accuracy: 0.5854 - val_loss: 1.6619 - val_accuracy: 0.5172\n",
      "Epoch 36/150\n",
      "57/57 [==============================] - 17s 301ms/step - loss: 1.5912 - accuracy: 0.6055 - val_loss: 1.4804 - val_accuracy: 0.6140\n",
      "Epoch 37/150\n",
      "57/57 [==============================] - 20s 350ms/step - loss: 1.5907 - accuracy: 0.5929 - val_loss: 1.4868 - val_accuracy: 0.6029\n",
      "Epoch 38/150\n",
      "57/57 [==============================] - 22s 380ms/step - loss: 1.5648 - accuracy: 0.6112 - val_loss: 1.6172 - val_accuracy: 0.5339\n",
      "Epoch 39/150\n",
      "57/57 [==============================] - 23s 411ms/step - loss: 1.5037 - accuracy: 0.6145 - val_loss: 1.5445 - val_accuracy: 0.5751\n",
      "Epoch 40/150\n",
      "57/57 [==============================] - 23s 405ms/step - loss: 1.5146 - accuracy: 0.6189 - val_loss: 1.4534 - val_accuracy: 0.6062\n",
      "Epoch 41/150\n",
      "57/57 [==============================] - 19s 338ms/step - loss: 1.4200 - accuracy: 0.6491 - val_loss: 1.5656 - val_accuracy: 0.5640\n",
      "Epoch 42/150\n",
      "57/57 [==============================] - 19s 333ms/step - loss: 1.4306 - accuracy: 0.6318 - val_loss: 1.4971 - val_accuracy: 0.5806\n",
      "Epoch 43/150\n",
      "57/57 [==============================] - 19s 332ms/step - loss: 1.4515 - accuracy: 0.6379 - val_loss: 1.5409 - val_accuracy: 0.5929\n",
      "Epoch 44/150\n",
      "57/57 [==============================] - 19s 331ms/step - loss: 1.4267 - accuracy: 0.6363 - val_loss: 1.6194 - val_accuracy: 0.5551\n",
      "Epoch 45/150\n",
      "57/57 [==============================] - 19s 329ms/step - loss: 1.3757 - accuracy: 0.6627 - val_loss: 1.3899 - val_accuracy: 0.6318\n",
      "Epoch 46/150\n",
      "57/57 [==============================] - 19s 340ms/step - loss: 1.4144 - accuracy: 0.6485 - val_loss: 1.5433 - val_accuracy: 0.5784\n",
      "Epoch 47/150\n",
      "57/57 [==============================] - 20s 358ms/step - loss: 1.3969 - accuracy: 0.6504 - val_loss: 1.3708 - val_accuracy: 0.6541\n",
      "Epoch 48/150\n",
      "57/57 [==============================] - 21s 373ms/step - loss: 1.3411 - accuracy: 0.6738 - val_loss: 1.4582 - val_accuracy: 0.6129\n",
      "Epoch 49/150\n",
      "57/57 [==============================] - 22s 395ms/step - loss: 1.3606 - accuracy: 0.6653 - val_loss: 1.4111 - val_accuracy: 0.6251\n",
      "Epoch 50/150\n",
      "57/57 [==============================] - 23s 397ms/step - loss: 1.3398 - accuracy: 0.6538 - val_loss: 1.4188 - val_accuracy: 0.6185\n",
      "Epoch 51/150\n",
      "57/57 [==============================] - 23s 403ms/step - loss: 1.2919 - accuracy: 0.6827 - val_loss: 1.3783 - val_accuracy: 0.6452\n",
      "Epoch 52/150\n",
      "57/57 [==============================] - 23s 407ms/step - loss: 1.2860 - accuracy: 0.6775 - val_loss: 1.3188 - val_accuracy: 0.6452\n",
      "Epoch 53/150\n",
      "57/57 [==============================] - 18s 307ms/step - loss: 1.2444 - accuracy: 0.6951 - val_loss: 1.4149 - val_accuracy: 0.6129\n",
      "Epoch 54/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 1.2746 - accuracy: 0.6886 - val_loss: 1.3881 - val_accuracy: 0.6296\n",
      "Epoch 55/150\n",
      "57/57 [==============================] - 16s 288ms/step - loss: 1.2490 - accuracy: 0.6986 - val_loss: 1.3452 - val_accuracy: 0.6363\n",
      "Epoch 56/150\n",
      "57/57 [==============================] - 16s 286ms/step - loss: 1.2378 - accuracy: 0.7031 - val_loss: 1.3232 - val_accuracy: 0.6552\n",
      "Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 17s 290ms/step - loss: 1.2205 - accuracy: 0.7081 - val_loss: 1.7230 - val_accuracy: 0.5373\n",
      "Epoch 58/150\n",
      "57/57 [==============================] - 16s 288ms/step - loss: 1.2449 - accuracy: 0.6879 - val_loss: 1.4167 - val_accuracy: 0.6185\n",
      "Epoch 59/150\n",
      "57/57 [==============================] - 16s 288ms/step - loss: 1.1884 - accuracy: 0.7251 - val_loss: 1.5516 - val_accuracy: 0.5662\n",
      "Epoch 60/150\n",
      "57/57 [==============================] - 16s 286ms/step - loss: 1.1756 - accuracy: 0.7170 - val_loss: 1.5099 - val_accuracy: 0.5918\n",
      "Epoch 61/150\n",
      "57/57 [==============================] - 16s 287ms/step - loss: 1.1916 - accuracy: 0.7162 - val_loss: 1.5342 - val_accuracy: 0.5818\n",
      "Epoch 62/150\n",
      "57/57 [==============================] - 16s 285ms/step - loss: 1.1525 - accuracy: 0.7292 - val_loss: 1.2955 - val_accuracy: 0.6607\n",
      "Epoch 63/150\n",
      "57/57 [==============================] - 18s 316ms/step - loss: 1.1757 - accuracy: 0.7077 - val_loss: 1.2145 - val_accuracy: 0.7030\n",
      "Epoch 64/150\n",
      "57/57 [==============================] - 17s 302ms/step - loss: 1.1336 - accuracy: 0.7444 - val_loss: 1.3463 - val_accuracy: 0.6529\n",
      "Epoch 65/150\n",
      "57/57 [==============================] - 17s 301ms/step - loss: 1.1588 - accuracy: 0.7175 - val_loss: 1.3220 - val_accuracy: 0.6674\n",
      "Epoch 66/150\n",
      "57/57 [==============================] - 17s 302ms/step - loss: 1.1204 - accuracy: 0.7428 - val_loss: 1.2965 - val_accuracy: 0.6707\n",
      "Epoch 67/150\n",
      "57/57 [==============================] - 17s 295ms/step - loss: 1.1088 - accuracy: 0.7445 - val_loss: 1.4137 - val_accuracy: 0.6185\n",
      "Epoch 68/150\n",
      "57/57 [==============================] - 17s 299ms/step - loss: 1.1413 - accuracy: 0.7291 - val_loss: 1.2230 - val_accuracy: 0.6974\n",
      "Epoch 69/150\n",
      "57/57 [==============================] - 17s 301ms/step - loss: 1.0841 - accuracy: 0.7415 - val_loss: 1.3235 - val_accuracy: 0.6652\n",
      "Epoch 70/150\n",
      "57/57 [==============================] - 17s 301ms/step - loss: 1.1171 - accuracy: 0.7317 - val_loss: 1.2240 - val_accuracy: 0.7152\n",
      "Epoch 71/150\n",
      "57/57 [==============================] - 17s 300ms/step - loss: 1.1015 - accuracy: 0.7439 - val_loss: 1.2316 - val_accuracy: 0.6941\n",
      "Epoch 72/150\n",
      "57/57 [==============================] - 17s 299ms/step - loss: 1.0647 - accuracy: 0.7498 - val_loss: 1.1885 - val_accuracy: 0.7041\n",
      "Epoch 73/150\n",
      "57/57 [==============================] - 17s 294ms/step - loss: 1.0970 - accuracy: 0.7347 - val_loss: 1.2843 - val_accuracy: 0.6574\n",
      "Epoch 74/150\n",
      "57/57 [==============================] - 17s 299ms/step - loss: 1.0662 - accuracy: 0.7428 - val_loss: 1.1867 - val_accuracy: 0.7219\n",
      "Epoch 75/150\n",
      "57/57 [==============================] - 17s 301ms/step - loss: 1.0653 - accuracy: 0.7577 - val_loss: 1.2930 - val_accuracy: 0.6596\n",
      "Epoch 76/150\n",
      "57/57 [==============================] - 17s 299ms/step - loss: 1.0104 - accuracy: 0.7742 - val_loss: 1.1062 - val_accuracy: 0.7430\n",
      "Epoch 77/150\n",
      "57/57 [==============================] - 17s 305ms/step - loss: 1.0047 - accuracy: 0.7649 - val_loss: 1.1692 - val_accuracy: 0.7141\n",
      "Epoch 78/150\n",
      "57/57 [==============================] - 17s 302ms/step - loss: 1.0168 - accuracy: 0.7509 - val_loss: 1.0127 - val_accuracy: 0.7742\n",
      "Epoch 79/150\n",
      "57/57 [==============================] - 17s 307ms/step - loss: 1.0017 - accuracy: 0.7691 - val_loss: 1.3504 - val_accuracy: 0.6396\n",
      "Epoch 80/150\n",
      "57/57 [==============================] - 17s 300ms/step - loss: 1.0003 - accuracy: 0.7780 - val_loss: 1.1769 - val_accuracy: 0.7164\n",
      "Epoch 81/150\n",
      "57/57 [==============================] - 17s 302ms/step - loss: 0.9854 - accuracy: 0.7832 - val_loss: 1.0187 - val_accuracy: 0.7709\n",
      "Epoch 82/150\n",
      "57/57 [==============================] - 17s 304ms/step - loss: 0.9577 - accuracy: 0.7843 - val_loss: 1.0650 - val_accuracy: 0.7464\n",
      "Epoch 83/150\n",
      "57/57 [==============================] - 17s 305ms/step - loss: 1.0001 - accuracy: 0.7688 - val_loss: 1.1772 - val_accuracy: 0.7052\n",
      "Epoch 84/150\n",
      "57/57 [==============================] - 18s 318ms/step - loss: 0.9671 - accuracy: 0.7712 - val_loss: 1.0333 - val_accuracy: 0.7620\n",
      "Epoch 85/150\n",
      "57/57 [==============================] - 18s 321ms/step - loss: 0.9900 - accuracy: 0.7666 - val_loss: 1.1161 - val_accuracy: 0.7542\n",
      "Epoch 86/150\n",
      "57/57 [==============================] - 17s 302ms/step - loss: 0.9338 - accuracy: 0.7892 - val_loss: 0.9852 - val_accuracy: 0.7631\n",
      "Epoch 87/150\n",
      "57/57 [==============================] - 18s 323ms/step - loss: 0.9508 - accuracy: 0.7840 - val_loss: 1.0811 - val_accuracy: 0.7386\n",
      "Epoch 88/150\n",
      "57/57 [==============================] - 18s 316ms/step - loss: 0.9582 - accuracy: 0.7780 - val_loss: 1.0244 - val_accuracy: 0.7620\n",
      "Epoch 89/150\n",
      "57/57 [==============================] - 17s 299ms/step - loss: 0.9036 - accuracy: 0.7887 - val_loss: 1.0366 - val_accuracy: 0.7631\n",
      "Epoch 90/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 0.9854 - accuracy: 0.7758 - val_loss: 1.1484 - val_accuracy: 0.7353\n",
      "Epoch 91/150\n",
      "57/57 [==============================] - 17s 300ms/step - loss: 0.9336 - accuracy: 0.7806 - val_loss: 1.0998 - val_accuracy: 0.7308\n",
      "Epoch 92/150\n",
      "57/57 [==============================] - 17s 292ms/step - loss: 0.9175 - accuracy: 0.7908 - val_loss: 1.1578 - val_accuracy: 0.7264\n",
      "Epoch 93/150\n",
      "57/57 [==============================] - 17s 301ms/step - loss: 0.8829 - accuracy: 0.8027 - val_loss: 1.0105 - val_accuracy: 0.7575\n",
      "Epoch 94/150\n",
      "57/57 [==============================] - 17s 292ms/step - loss: 0.8741 - accuracy: 0.8116 - val_loss: 1.1797 - val_accuracy: 0.7164\n",
      "Epoch 95/150\n",
      "57/57 [==============================] - 17s 290ms/step - loss: 0.9029 - accuracy: 0.7970 - val_loss: 1.2705 - val_accuracy: 0.6830\n",
      "Epoch 96/150\n",
      "57/57 [==============================] - 17s 290ms/step - loss: 0.9148 - accuracy: 0.7966 - val_loss: 1.3471 - val_accuracy: 0.6574\n",
      "Epoch 97/150\n",
      "57/57 [==============================] - 17s 291ms/step - loss: 0.8767 - accuracy: 0.7953 - val_loss: 0.9594 - val_accuracy: 0.7775\n",
      "Epoch 98/150\n",
      "57/57 [==============================] - 16s 289ms/step - loss: 0.8763 - accuracy: 0.7969 - val_loss: 1.1110 - val_accuracy: 0.7364\n",
      "Epoch 99/150\n",
      "57/57 [==============================] - 17s 292ms/step - loss: 0.8815 - accuracy: 0.7987 - val_loss: 1.0592 - val_accuracy: 0.7542\n",
      "Epoch 100/150\n",
      "57/57 [==============================] - 17s 295ms/step - loss: 0.8651 - accuracy: 0.7919 - val_loss: 1.2056 - val_accuracy: 0.7052\n",
      "Epoch 101/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 0.8635 - accuracy: 0.8082 - val_loss: 1.0390 - val_accuracy: 0.7697\n",
      "Epoch 102/150\n",
      "57/57 [==============================] - 17s 294ms/step - loss: 0.8535 - accuracy: 0.8091 - val_loss: 1.3154 - val_accuracy: 0.6641\n",
      "Epoch 103/150\n",
      "57/57 [==============================] - 17s 295ms/step - loss: 0.8502 - accuracy: 0.8081 - val_loss: 0.9586 - val_accuracy: 0.7942\n",
      "Epoch 104/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 0.8826 - accuracy: 0.7914 - val_loss: 1.0700 - val_accuracy: 0.7508\n",
      "Epoch 105/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 0.8075 - accuracy: 0.8288 - val_loss: 1.1397 - val_accuracy: 0.7330\n",
      "Epoch 106/150\n",
      "57/57 [==============================] - 17s 295ms/step - loss: 0.8037 - accuracy: 0.8247 - val_loss: 1.1882 - val_accuracy: 0.7008\n",
      "Epoch 107/150\n",
      "57/57 [==============================] - 17s 301ms/step - loss: 0.8229 - accuracy: 0.8135 - val_loss: 1.0098 - val_accuracy: 0.7753\n",
      "Epoch 108/150\n",
      "57/57 [==============================] - 17s 296ms/step - loss: 0.7898 - accuracy: 0.8310 - val_loss: 1.0510 - val_accuracy: 0.7620\n",
      "Epoch 109/150\n",
      "57/57 [==============================] - 17s 290ms/step - loss: 0.7943 - accuracy: 0.8211 - val_loss: 1.0388 - val_accuracy: 0.7519\n",
      "Epoch 110/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 0.8265 - accuracy: 0.8185 - val_loss: 1.1039 - val_accuracy: 0.7364\n",
      "Epoch 111/150\n",
      "57/57 [==============================] - 17s 298ms/step - loss: 0.7930 - accuracy: 0.8306 - val_loss: 1.2316 - val_accuracy: 0.6852\n",
      "Epoch 112/150\n",
      "57/57 [==============================] - 16s 282ms/step - loss: 0.7764 - accuracy: 0.8371 - val_loss: 0.9679 - val_accuracy: 0.7731\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 16s 278ms/step - loss: 0.7599 - accuracy: 0.8335 - val_loss: 1.0245 - val_accuracy: 0.7686\n",
      "Epoch 114/150\n",
      "57/57 [==============================] - 16s 278ms/step - loss: 0.8222 - accuracy: 0.8147 - val_loss: 1.0422 - val_accuracy: 0.7608\n",
      "Epoch 115/150\n",
      "57/57 [==============================] - 16s 278ms/step - loss: 0.8074 - accuracy: 0.8138 - val_loss: 1.1364 - val_accuracy: 0.7264\n",
      "Epoch 116/150\n",
      "57/57 [==============================] - 16s 276ms/step - loss: 0.7828 - accuracy: 0.8341 - val_loss: 1.1074 - val_accuracy: 0.7497\n",
      "Epoch 117/150\n",
      "57/57 [==============================] - 16s 280ms/step - loss: 0.7526 - accuracy: 0.8421 - val_loss: 0.9119 - val_accuracy: 0.7920\n",
      "Epoch 118/150\n",
      "57/57 [==============================] - 16s 282ms/step - loss: 0.7749 - accuracy: 0.8365 - val_loss: 1.1048 - val_accuracy: 0.7375\n",
      "Epoch 119/150\n",
      "57/57 [==============================] - 16s 281ms/step - loss: 0.7464 - accuracy: 0.8399 - val_loss: 1.0505 - val_accuracy: 0.7653\n",
      "Epoch 120/150\n",
      "57/57 [==============================] - 16s 276ms/step - loss: 0.7404 - accuracy: 0.8451 - val_loss: 0.9772 - val_accuracy: 0.7731\n",
      "Epoch 121/150\n",
      "57/57 [==============================] - 16s 276ms/step - loss: 0.7672 - accuracy: 0.8345 - val_loss: 1.0740 - val_accuracy: 0.7442\n",
      "Epoch 122/150\n",
      "57/57 [==============================] - 16s 278ms/step - loss: 0.7211 - accuracy: 0.8562 - val_loss: 1.0045 - val_accuracy: 0.7675\n",
      "Epoch 123/150\n",
      "57/57 [==============================] - 16s 281ms/step - loss: 0.7587 - accuracy: 0.8365 - val_loss: 1.0237 - val_accuracy: 0.7642\n",
      "Epoch 124/150\n",
      "57/57 [==============================] - 16s 276ms/step - loss: 0.7104 - accuracy: 0.8557 - val_loss: 1.0062 - val_accuracy: 0.7620\n",
      "Epoch 125/150\n",
      "57/57 [==============================] - 16s 280ms/step - loss: 0.7340 - accuracy: 0.8405 - val_loss: 1.2218 - val_accuracy: 0.7119\n",
      "Epoch 126/150\n",
      "57/57 [==============================] - 16s 275ms/step - loss: 0.7362 - accuracy: 0.8402 - val_loss: 1.0083 - val_accuracy: 0.7731\n",
      "Epoch 127/150\n",
      "57/57 [==============================] - 16s 279ms/step - loss: 0.7172 - accuracy: 0.8483 - val_loss: 0.9930 - val_accuracy: 0.7664\n",
      "Epoch 128/150\n",
      "57/57 [==============================] - 16s 279ms/step - loss: 0.7595 - accuracy: 0.8349 - val_loss: 0.9829 - val_accuracy: 0.7653\n",
      "Epoch 129/150\n",
      "57/57 [==============================] - 16s 277ms/step - loss: 0.7590 - accuracy: 0.8318 - val_loss: 1.0205 - val_accuracy: 0.7642\n",
      "Epoch 130/150\n",
      "57/57 [==============================] - 16s 280ms/step - loss: 0.7278 - accuracy: 0.8384 - val_loss: 0.9792 - val_accuracy: 0.7798\n",
      "Epoch 131/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 0.7003 - accuracy: 0.8499 - val_loss: 0.9019 - val_accuracy: 0.7998\n",
      "Epoch 132/150\n",
      "57/57 [==============================] - 16s 280ms/step - loss: 0.6691 - accuracy: 0.8697 - val_loss: 1.0271 - val_accuracy: 0.7675\n",
      "Epoch 133/150\n",
      "57/57 [==============================] - 16s 282ms/step - loss: 0.7187 - accuracy: 0.8418 - val_loss: 1.0447 - val_accuracy: 0.7497\n",
      "Epoch 134/150\n",
      "57/57 [==============================] - 16s 281ms/step - loss: 0.7161 - accuracy: 0.8539 - val_loss: 0.8367 - val_accuracy: 0.8198\n",
      "Epoch 135/150\n",
      "57/57 [==============================] - 16s 279ms/step - loss: 0.6817 - accuracy: 0.8592 - val_loss: 0.9509 - val_accuracy: 0.7809\n",
      "Epoch 136/150\n",
      "57/57 [==============================] - 16s 280ms/step - loss: 0.6731 - accuracy: 0.8601 - val_loss: 1.0681 - val_accuracy: 0.7408\n",
      "Epoch 137/150\n",
      "57/57 [==============================] - 16s 282ms/step - loss: 0.6954 - accuracy: 0.8509 - val_loss: 1.0490 - val_accuracy: 0.7620\n",
      "Epoch 138/150\n",
      "57/57 [==============================] - 16s 284ms/step - loss: 0.6727 - accuracy: 0.8673 - val_loss: 0.9400 - val_accuracy: 0.7853\n",
      "Epoch 139/150\n",
      "57/57 [==============================] - 16s 284ms/step - loss: 0.6757 - accuracy: 0.8614 - val_loss: 1.0160 - val_accuracy: 0.7731\n",
      "Epoch 140/150\n",
      "57/57 [==============================] - 16s 280ms/step - loss: 0.6775 - accuracy: 0.8648 - val_loss: 1.1062 - val_accuracy: 0.7419\n",
      "Epoch 141/150\n",
      "57/57 [==============================] - 16s 282ms/step - loss: 0.6811 - accuracy: 0.8634 - val_loss: 0.8467 - val_accuracy: 0.8176\n",
      "Epoch 142/150\n",
      "57/57 [==============================] - 16s 281ms/step - loss: 0.6676 - accuracy: 0.8557 - val_loss: 0.9405 - val_accuracy: 0.7887\n",
      "Epoch 143/150\n",
      "57/57 [==============================] - 16s 279ms/step - loss: 0.6603 - accuracy: 0.8621 - val_loss: 0.9160 - val_accuracy: 0.7853\n",
      "Epoch 144/150\n",
      "57/57 [==============================] - 16s 282ms/step - loss: 0.6337 - accuracy: 0.8732 - val_loss: 0.8819 - val_accuracy: 0.8053\n",
      "Epoch 145/150\n",
      "57/57 [==============================] - 16s 284ms/step - loss: 0.6697 - accuracy: 0.8583 - val_loss: 1.0084 - val_accuracy: 0.7653\n",
      "Epoch 146/150\n",
      "57/57 [==============================] - 16s 287ms/step - loss: 0.6604 - accuracy: 0.8650 - val_loss: 1.3046 - val_accuracy: 0.6974\n",
      "Epoch 147/150\n",
      "57/57 [==============================] - 14s 237ms/step - loss: 0.6343 - accuracy: 0.8720 - val_loss: 0.9164 - val_accuracy: 0.7953\n",
      "Epoch 148/150\n",
      "57/57 [==============================] - 10s 176ms/step - loss: 0.6377 - accuracy: 0.8743 - val_loss: 1.0446 - val_accuracy: 0.7586\n",
      "Epoch 149/150\n",
      "57/57 [==============================] - 10s 178ms/step - loss: 0.6482 - accuracy: 0.8774 - val_loss: 0.9572 - val_accuracy: 0.7664\n",
      "Epoch 150/150\n",
      "57/57 [==============================] - 10s 179ms/step - loss: 0.6137 - accuracy: 0.8788 - val_loss: 0.8658 - val_accuracy: 0.8131\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "          y_train, \n",
    "          validation_data = (X_validation, y_validation), \n",
    "          batch_size = 64, \n",
    "          epochs = 150,\n",
    "          )\n",
    "\n",
    "# history = model.fit(X_train, \n",
    "#           y_train, \n",
    "#           validation_data = (X_validation, y_validation), \n",
    "#           batch_size = 64, \n",
    "#           epochs = 200,\n",
    "#           callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 19ms/step - loss: 0.7992 - accuracy: 0.8238\n"
     ]
    }
   ],
   "source": [
    "test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Accuracy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(history):\n",
    "    fig, axs = plt.subplots(2)\n",
    "\n",
    "    # Accuracy Subplot\n",
    "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].set_title(\"Accuracy Eval\")\n",
    "\n",
    "    # Error Subplot\n",
    "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
    "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
    "    axs[1].set_ylabel(\"Error\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Error Eval\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'History' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-52d09bb01d1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-c453641e7ec7>\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(history)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# Accuracy Subplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"test accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'History' object is not subscriptable"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X_prediction, y_prediction):\n",
    "    \n",
    "    X = X[np.newaxis, ...]\n",
    "    \n",
    "    # Plot predictions to a 2D Array\n",
    "    predictions = model.predict(X_temp)\n",
    "    \n",
    "    predicted_index = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    print(f'Target: {y}, Predicted label: {predicted_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prediction = X_test[200]\n",
    "y_prediction = y_test[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'X' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-c4893db897ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_prediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_prediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-a9a3f50f0bd0>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(model, X_prediction, y_prediction)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_prediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_prediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Plot predictions to a 2D Array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'X' referenced before assignment"
     ]
    }
   ],
   "source": [
    "predict(model, X_prediction, y_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/cnn_model_10_segs_per_track.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
