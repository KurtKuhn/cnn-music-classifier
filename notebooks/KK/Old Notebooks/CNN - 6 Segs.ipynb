{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.python.keras import regularizers\n",
    "\n",
    "data_path = '../audio_data_MFCC/6_segs_per_track_output.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data (dataset_path, data1 = 'mfcc', data2 = 'labels'):\n",
    "    \n",
    "    np_file = np.load(dataset_path)\n",
    "    \n",
    "    return np_file[data1], np_file[data2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(data_path, test_size, validation_size):\n",
    "    \n",
    "    # load data\n",
    "    X, y = load_data(data_path, 'mfcc', 'labels')\n",
    "    \n",
    "    # create train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    \n",
    "    # create train/validation split\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, \n",
    "                                                                    y_train, \n",
    "                                                                    test_size=validation_size)\n",
    "    \n",
    "    \n",
    "    X_train = X_train[..., np.newaxis] # 4d array -> (num_samples, 130, 13, 1)\n",
    "    X_validation = X_validation[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "    \n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets('../audio_data_MFCC/6_segs_per_track_output.npz', 0.25, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model(input_shape):\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # 1st conv layer\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 2nd conv layer\n",
    "    model.add(keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.Dropout(0.25))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    # 3rd conv layer\n",
    "    model.add(keras.layers.Conv2D(16, (1, 1), activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "    # flatten output and feed it into dense layer\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "\n",
    "    # output layer\n",
    "    model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3595, 216, 13, 1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build and Compile The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build CNN model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "model = build_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "optimizer = keras.optimizers.Adam(learning_rate = 0.00015)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in an early stop to avoid overtraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='accuracy', mode='min', verbose=1, patience=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "57/57 [==============================] - 13s 210ms/step - loss: 3.5473 - accuracy: 0.1182 - val_loss: 3.1243 - val_accuracy: 0.0957\n",
      "Epoch 2/150\n",
      "57/57 [==============================] - 11s 195ms/step - loss: 3.2601 - accuracy: 0.1510 - val_loss: 2.9493 - val_accuracy: 0.2380\n",
      "Epoch 3/150\n",
      "57/57 [==============================] - 11s 189ms/step - loss: 3.0691 - accuracy: 0.1953 - val_loss: 2.8038 - val_accuracy: 0.3103\n",
      "Epoch 4/150\n",
      "57/57 [==============================] - 16s 278ms/step - loss: 2.9058 - accuracy: 0.2416 - val_loss: 2.7013 - val_accuracy: 0.3281\n",
      "Epoch 5/150\n",
      "57/57 [==============================] - 15s 257ms/step - loss: 2.8362 - accuracy: 0.2733 - val_loss: 2.6307 - val_accuracy: 0.3359\n",
      "Epoch 6/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 2.7591 - accuracy: 0.2790 - val_loss: 2.5157 - val_accuracy: 0.3838\n",
      "Epoch 7/150\n",
      "57/57 [==============================] - 17s 292ms/step - loss: 2.6788 - accuracy: 0.2977 - val_loss: 2.4737 - val_accuracy: 0.3838\n",
      "Epoch 8/150\n",
      "57/57 [==============================] - 17s 294ms/step - loss: 2.5701 - accuracy: 0.3145 - val_loss: 2.3918 - val_accuracy: 0.4004\n",
      "Epoch 9/150\n",
      "57/57 [==============================] - 17s 291ms/step - loss: 2.5057 - accuracy: 0.3393 - val_loss: 2.2840 - val_accuracy: 0.4594\n",
      "Epoch 10/150\n",
      "57/57 [==============================] - 17s 291ms/step - loss: 2.4346 - accuracy: 0.3561 - val_loss: 2.1840 - val_accuracy: 0.4883\n",
      "Epoch 11/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 2.3880 - accuracy: 0.3643 - val_loss: 2.1305 - val_accuracy: 0.4816\n",
      "Epoch 12/150\n",
      "57/57 [==============================] - 23s 411ms/step - loss: 2.3275 - accuracy: 0.3857 - val_loss: 2.0643 - val_accuracy: 0.5172\n",
      "Epoch 13/150\n",
      "57/57 [==============================] - 22s 382ms/step - loss: 2.2262 - accuracy: 0.4157 - val_loss: 2.0142 - val_accuracy: 0.5384\n",
      "Epoch 14/150\n",
      "57/57 [==============================] - 17s 292ms/step - loss: 2.1846 - accuracy: 0.4173 - val_loss: 1.9637 - val_accuracy: 0.5595\n",
      "Epoch 15/150\n",
      "57/57 [==============================] - 19s 338ms/step - loss: 2.1659 - accuracy: 0.4162 - val_loss: 1.9188 - val_accuracy: 0.5806\n",
      "Epoch 16/150\n",
      "57/57 [==============================] - 20s 353ms/step - loss: 2.1090 - accuracy: 0.4586 - val_loss: 1.8875 - val_accuracy: 0.5818\n",
      "Epoch 17/150\n",
      "57/57 [==============================] - 18s 319ms/step - loss: 2.0824 - accuracy: 0.4357 - val_loss: 1.8507 - val_accuracy: 0.5818\n",
      "Epoch 18/150\n",
      "57/57 [==============================] - 18s 320ms/step - loss: 1.9938 - accuracy: 0.4733 - val_loss: 1.8276 - val_accuracy: 0.5729\n",
      "Epoch 19/150\n",
      "57/57 [==============================] - 18s 320ms/step - loss: 1.9759 - accuracy: 0.4824 - val_loss: 1.7982 - val_accuracy: 0.5818\n",
      "Epoch 20/150\n",
      "57/57 [==============================] - 17s 290ms/step - loss: 1.9668 - accuracy: 0.4865 - val_loss: 1.7387 - val_accuracy: 0.6029\n",
      "Epoch 21/150\n",
      "57/57 [==============================] - 17s 296ms/step - loss: 1.9631 - accuracy: 0.4765 - val_loss: 1.7414 - val_accuracy: 0.6018\n",
      "Epoch 22/150\n",
      "57/57 [==============================] - 17s 305ms/step - loss: 1.8897 - accuracy: 0.5071 - val_loss: 1.7387 - val_accuracy: 0.5640\n",
      "Epoch 23/150\n",
      "57/57 [==============================] - 20s 346ms/step - loss: 1.8451 - accuracy: 0.5140 - val_loss: 1.7212 - val_accuracy: 0.5684\n",
      "Epoch 24/150\n",
      "57/57 [==============================] - 17s 294ms/step - loss: 1.8452 - accuracy: 0.5197 - val_loss: 1.6322 - val_accuracy: 0.6218\n",
      "Epoch 25/150\n",
      "57/57 [==============================] - 17s 296ms/step - loss: 1.7870 - accuracy: 0.5334 - val_loss: 1.5861 - val_accuracy: 0.6296\n",
      "Epoch 26/150\n",
      "57/57 [==============================] - 17s 307ms/step - loss: 1.7784 - accuracy: 0.5348 - val_loss: 1.5890 - val_accuracy: 0.6263\n",
      "Epoch 27/150\n",
      "57/57 [==============================] - 17s 292ms/step - loss: 1.7432 - accuracy: 0.5471 - val_loss: 1.6001 - val_accuracy: 0.6073\n",
      "Epoch 28/150\n",
      "57/57 [==============================] - 16s 289ms/step - loss: 1.7020 - accuracy: 0.5587 - val_loss: 1.5828 - val_accuracy: 0.5962\n",
      "Epoch 29/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 1.7353 - accuracy: 0.5422 - val_loss: 1.5604 - val_accuracy: 0.6174\n",
      "Epoch 30/150\n",
      "57/57 [==============================] - 16s 289ms/step - loss: 1.6727 - accuracy: 0.5613 - val_loss: 1.5633 - val_accuracy: 0.6018\n",
      "Epoch 31/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 1.6887 - accuracy: 0.5646 - val_loss: 1.4860 - val_accuracy: 0.6440\n",
      "Epoch 32/150\n",
      "57/57 [==============================] - 17s 291ms/step - loss: 1.6315 - accuracy: 0.5689 - val_loss: 1.4948 - val_accuracy: 0.6630\n",
      "Epoch 33/150\n",
      "57/57 [==============================] - 16s 286ms/step - loss: 1.6023 - accuracy: 0.5799 - val_loss: 1.6014 - val_accuracy: 0.5940\n",
      "Epoch 34/150\n",
      "57/57 [==============================] - 17s 292ms/step - loss: 1.5961 - accuracy: 0.5796 - val_loss: 1.4334 - val_accuracy: 0.6652\n",
      "Epoch 35/150\n",
      "57/57 [==============================] - 16s 289ms/step - loss: 1.5845 - accuracy: 0.5706 - val_loss: 1.4424 - val_accuracy: 0.6596\n",
      "Epoch 36/150\n",
      "57/57 [==============================] - 17s 290ms/step - loss: 1.5607 - accuracy: 0.5828 - val_loss: 1.4275 - val_accuracy: 0.6541\n",
      "Epoch 37/150\n",
      "57/57 [==============================] - 17s 291ms/step - loss: 1.5067 - accuracy: 0.5951 - val_loss: 1.4775 - val_accuracy: 0.6285\n",
      "Epoch 38/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 1.5428 - accuracy: 0.5971 - val_loss: 1.4147 - val_accuracy: 0.6474\n",
      "Epoch 39/150\n",
      "57/57 [==============================] - 17s 295ms/step - loss: 1.5088 - accuracy: 0.6077 - val_loss: 1.3488 - val_accuracy: 0.6785\n",
      "Epoch 40/150\n",
      "57/57 [==============================] - 18s 322ms/step - loss: 1.4592 - accuracy: 0.6155 - val_loss: 1.3990 - val_accuracy: 0.6529\n",
      "Epoch 41/150\n",
      "57/57 [==============================] - 21s 367ms/step - loss: 1.4318 - accuracy: 0.6307 - val_loss: 1.4021 - val_accuracy: 0.6440\n",
      "Epoch 42/150\n",
      "57/57 [==============================] - 22s 391ms/step - loss: 1.4170 - accuracy: 0.6381 - val_loss: 1.3330 - val_accuracy: 0.6796\n",
      "Epoch 43/150\n",
      "57/57 [==============================] - 23s 410ms/step - loss: 1.4211 - accuracy: 0.6322 - val_loss: 1.3731 - val_accuracy: 0.6507\n",
      "Epoch 44/150\n",
      "57/57 [==============================] - 22s 384ms/step - loss: 1.4099 - accuracy: 0.6339 - val_loss: 1.2822 - val_accuracy: 0.6952\n",
      "Epoch 45/150\n",
      "57/57 [==============================] - 19s 338ms/step - loss: 1.3568 - accuracy: 0.6510 - val_loss: 1.2998 - val_accuracy: 0.6830\n",
      "Epoch 46/150\n",
      "57/57 [==============================] - 19s 330ms/step - loss: 1.3665 - accuracy: 0.6522 - val_loss: 1.3259 - val_accuracy: 0.6674\n",
      "Epoch 47/150\n",
      "57/57 [==============================] - 19s 334ms/step - loss: 1.3483 - accuracy: 0.6597 - val_loss: 1.2970 - val_accuracy: 0.6830\n",
      "Epoch 48/150\n",
      "57/57 [==============================] - 19s 331ms/step - loss: 1.3439 - accuracy: 0.6584 - val_loss: 1.2749 - val_accuracy: 0.6863\n",
      "Epoch 49/150\n",
      "57/57 [==============================] - 19s 331ms/step - loss: 1.3212 - accuracy: 0.6721 - val_loss: 1.2190 - val_accuracy: 0.7041\n",
      "Epoch 50/150\n",
      "57/57 [==============================] - 20s 356ms/step - loss: 1.2993 - accuracy: 0.6726 - val_loss: 1.2720 - val_accuracy: 0.6952\n",
      "Epoch 51/150\n",
      "57/57 [==============================] - 20s 345ms/step - loss: 1.3166 - accuracy: 0.6703 - val_loss: 1.2456 - val_accuracy: 0.6930\n",
      "Epoch 52/150\n",
      "57/57 [==============================] - 23s 399ms/step - loss: 1.2823 - accuracy: 0.6796 - val_loss: 1.1807 - val_accuracy: 0.7264\n",
      "Epoch 53/150\n",
      "57/57 [==============================] - 23s 396ms/step - loss: 1.2562 - accuracy: 0.6860 - val_loss: 1.2487 - val_accuracy: 0.7008\n",
      "Epoch 54/150\n",
      "57/57 [==============================] - 23s 402ms/step - loss: 1.2353 - accuracy: 0.6853 - val_loss: 1.2035 - val_accuracy: 0.6997\n",
      "Epoch 55/150\n",
      "57/57 [==============================] - 23s 407ms/step - loss: 1.2741 - accuracy: 0.6759 - val_loss: 1.1582 - val_accuracy: 0.7175\n",
      "Epoch 56/150\n",
      "57/57 [==============================] - 21s 370ms/step - loss: 1.2145 - accuracy: 0.6960 - val_loss: 1.1825 - val_accuracy: 0.7130\n",
      "Epoch 57/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 17s 297ms/step - loss: 1.2285 - accuracy: 0.6882 - val_loss: 1.2152 - val_accuracy: 0.7141\n",
      "Epoch 58/150\n",
      "57/57 [==============================] - 16s 286ms/step - loss: 1.2389 - accuracy: 0.6844 - val_loss: 1.2202 - val_accuracy: 0.6986\n",
      "Epoch 59/150\n",
      "57/57 [==============================] - 16s 286ms/step - loss: 1.1980 - accuracy: 0.6954 - val_loss: 1.2077 - val_accuracy: 0.7186\n",
      "Epoch 60/150\n",
      "57/57 [==============================] - 16s 284ms/step - loss: 1.2667 - accuracy: 0.6722 - val_loss: 1.1861 - val_accuracy: 0.7141\n",
      "Epoch 61/150\n",
      "57/57 [==============================] - 17s 294ms/step - loss: 1.1653 - accuracy: 0.7045 - val_loss: 1.1524 - val_accuracy: 0.7297\n",
      "Epoch 62/150\n",
      "57/57 [==============================] - 16s 289ms/step - loss: 1.2011 - accuracy: 0.6968 - val_loss: 1.2982 - val_accuracy: 0.6663\n",
      "Epoch 63/150\n",
      "57/57 [==============================] - 16s 288ms/step - loss: 1.1879 - accuracy: 0.7067 - val_loss: 1.2326 - val_accuracy: 0.6763\n",
      "Epoch 64/150\n",
      "57/57 [==============================] - 16s 285ms/step - loss: 1.2083 - accuracy: 0.6994 - val_loss: 1.1788 - val_accuracy: 0.7141\n",
      "Epoch 65/150\n",
      "57/57 [==============================] - 16s 284ms/step - loss: 1.1324 - accuracy: 0.7163 - val_loss: 1.1942 - val_accuracy: 0.6930\n",
      "Epoch 66/150\n",
      "57/57 [==============================] - 17s 302ms/step - loss: 1.1522 - accuracy: 0.7205 - val_loss: 1.0573 - val_accuracy: 0.7475\n",
      "Epoch 67/150\n",
      "57/57 [==============================] - 17s 301ms/step - loss: 1.0843 - accuracy: 0.7395 - val_loss: 1.1405 - val_accuracy: 0.7286\n",
      "Epoch 68/150\n",
      "57/57 [==============================] - 18s 312ms/step - loss: 1.1067 - accuracy: 0.7347 - val_loss: 1.0785 - val_accuracy: 0.7453\n",
      "Epoch 69/150\n",
      "57/57 [==============================] - 17s 298ms/step - loss: 1.1534 - accuracy: 0.7127 - val_loss: 1.0965 - val_accuracy: 0.7419\n",
      "Epoch 70/150\n",
      "57/57 [==============================] - 17s 292ms/step - loss: 1.1184 - accuracy: 0.7315 - val_loss: 1.2760 - val_accuracy: 0.6719\n",
      "Epoch 71/150\n",
      "57/57 [==============================] - 17s 298ms/step - loss: 1.0944 - accuracy: 0.7281 - val_loss: 1.1535 - val_accuracy: 0.6974\n",
      "Epoch 72/150\n",
      "57/57 [==============================] - 17s 292ms/step - loss: 1.0572 - accuracy: 0.7479 - val_loss: 1.0575 - val_accuracy: 0.7586\n",
      "Epoch 73/150\n",
      "57/57 [==============================] - 17s 298ms/step - loss: 1.0456 - accuracy: 0.7509 - val_loss: 1.0719 - val_accuracy: 0.7531\n",
      "Epoch 74/150\n",
      "57/57 [==============================] - 17s 301ms/step - loss: 1.0239 - accuracy: 0.7621 - val_loss: 1.2178 - val_accuracy: 0.7075\n",
      "Epoch 75/150\n",
      "57/57 [==============================] - 17s 298ms/step - loss: 1.0440 - accuracy: 0.7494 - val_loss: 1.0391 - val_accuracy: 0.7642\n",
      "Epoch 76/150\n",
      "57/57 [==============================] - 17s 299ms/step - loss: 1.0326 - accuracy: 0.7531 - val_loss: 0.9865 - val_accuracy: 0.7809\n",
      "Epoch 77/150\n",
      "57/57 [==============================] - 17s 297ms/step - loss: 1.0443 - accuracy: 0.7509 - val_loss: 1.1928 - val_accuracy: 0.7008\n",
      "Epoch 78/150\n",
      "57/57 [==============================] - 17s 299ms/step - loss: 1.0256 - accuracy: 0.7537 - val_loss: 1.2727 - val_accuracy: 0.6830\n",
      "Epoch 79/150\n",
      "57/57 [==============================] - 17s 301ms/step - loss: 1.0391 - accuracy: 0.7405 - val_loss: 1.2098 - val_accuracy: 0.6908\n",
      "Epoch 80/150\n",
      "57/57 [==============================] - 17s 306ms/step - loss: 1.0177 - accuracy: 0.7624 - val_loss: 1.2943 - val_accuracy: 0.6630\n",
      "Epoch 81/150\n",
      "57/57 [==============================] - 17s 301ms/step - loss: 0.9875 - accuracy: 0.7684 - val_loss: 1.1704 - val_accuracy: 0.6986\n",
      "Epoch 82/150\n",
      "57/57 [==============================] - 17s 303ms/step - loss: 1.0077 - accuracy: 0.7615 - val_loss: 1.0802 - val_accuracy: 0.7286\n",
      "Epoch 83/150\n",
      "57/57 [==============================] - 17s 299ms/step - loss: 0.9320 - accuracy: 0.7785 - val_loss: 1.1291 - val_accuracy: 0.7241\n",
      "Epoch 84/150\n",
      "57/57 [==============================] - 17s 302ms/step - loss: 0.9783 - accuracy: 0.7743 - val_loss: 0.9761 - val_accuracy: 0.7764\n",
      "Epoch 85/150\n",
      "57/57 [==============================] - 17s 295ms/step - loss: 0.9264 - accuracy: 0.7880 - val_loss: 1.0277 - val_accuracy: 0.7519\n",
      "Epoch 86/150\n",
      "57/57 [==============================] - 17s 292ms/step - loss: 0.9367 - accuracy: 0.7899 - val_loss: 1.0631 - val_accuracy: 0.7497\n",
      "Epoch 87/150\n",
      "57/57 [==============================] - 18s 311ms/step - loss: 0.9168 - accuracy: 0.7832 - val_loss: 0.9741 - val_accuracy: 0.7820\n",
      "Epoch 88/150\n",
      "57/57 [==============================] - 17s 307ms/step - loss: 0.9295 - accuracy: 0.7774 - val_loss: 1.0604 - val_accuracy: 0.7653\n",
      "Epoch 89/150\n",
      "57/57 [==============================] - 18s 321ms/step - loss: 0.9300 - accuracy: 0.7758 - val_loss: 1.0698 - val_accuracy: 0.7364\n",
      "Epoch 90/150\n",
      "57/57 [==============================] - 18s 311ms/step - loss: 0.9271 - accuracy: 0.7840 - val_loss: 1.0300 - val_accuracy: 0.7553\n",
      "Epoch 91/150\n",
      "57/57 [==============================] - 18s 323ms/step - loss: 0.9440 - accuracy: 0.7794 - val_loss: 1.0965 - val_accuracy: 0.7130\n",
      "Epoch 92/150\n",
      "57/57 [==============================] - 18s 313ms/step - loss: 0.9672 - accuracy: 0.7579 - val_loss: 1.0689 - val_accuracy: 0.7275\n",
      "Epoch 93/150\n",
      "57/57 [==============================] - 16s 290ms/step - loss: 0.9395 - accuracy: 0.7816 - val_loss: 1.1521 - val_accuracy: 0.7119\n",
      "Epoch 94/150\n",
      "57/57 [==============================] - 16s 289ms/step - loss: 0.8885 - accuracy: 0.7936 - val_loss: 0.8834 - val_accuracy: 0.7964\n",
      "Epoch 95/150\n",
      "57/57 [==============================] - 17s 299ms/step - loss: 0.9188 - accuracy: 0.7892 - val_loss: 1.0970 - val_accuracy: 0.7386\n",
      "Epoch 96/150\n",
      "57/57 [==============================] - 17s 295ms/step - loss: 0.8890 - accuracy: 0.8026 - val_loss: 0.9668 - val_accuracy: 0.7864\n",
      "Epoch 97/150\n",
      "57/57 [==============================] - 17s 296ms/step - loss: 0.8472 - accuracy: 0.8104 - val_loss: 0.9786 - val_accuracy: 0.7820\n",
      "Epoch 98/150\n",
      "57/57 [==============================] - 17s 295ms/step - loss: 0.8609 - accuracy: 0.7943 - val_loss: 1.0393 - val_accuracy: 0.7486\n",
      "Epoch 99/150\n",
      "57/57 [==============================] - 17s 291ms/step - loss: 0.8859 - accuracy: 0.7953 - val_loss: 1.1551 - val_accuracy: 0.7230\n",
      "Epoch 100/150\n",
      "57/57 [==============================] - 17s 294ms/step - loss: 0.8772 - accuracy: 0.7897 - val_loss: 1.0056 - val_accuracy: 0.7742\n",
      "Epoch 101/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 0.8614 - accuracy: 0.7969 - val_loss: 0.9914 - val_accuracy: 0.7686\n",
      "Epoch 102/150\n",
      "57/57 [==============================] - 17s 290ms/step - loss: 0.8801 - accuracy: 0.7987 - val_loss: 0.9113 - val_accuracy: 0.7931\n",
      "Epoch 103/150\n",
      "57/57 [==============================] - 17s 294ms/step - loss: 0.8142 - accuracy: 0.8129 - val_loss: 0.9590 - val_accuracy: 0.7675\n",
      "Epoch 104/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 0.8204 - accuracy: 0.8166 - val_loss: 0.9675 - val_accuracy: 0.7697\n",
      "Epoch 105/150\n",
      "57/57 [==============================] - 17s 292ms/step - loss: 0.8251 - accuracy: 0.8215 - val_loss: 1.0108 - val_accuracy: 0.7620\n",
      "Epoch 106/150\n",
      "57/57 [==============================] - 17s 291ms/step - loss: 0.8232 - accuracy: 0.8071 - val_loss: 0.9309 - val_accuracy: 0.7853\n",
      "Epoch 107/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 0.8274 - accuracy: 0.8159 - val_loss: 0.9853 - val_accuracy: 0.7764\n",
      "Epoch 108/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 0.8454 - accuracy: 0.8171 - val_loss: 1.0219 - val_accuracy: 0.7608\n",
      "Epoch 109/150\n",
      "57/57 [==============================] - 17s 294ms/step - loss: 0.8086 - accuracy: 0.8269 - val_loss: 1.1668 - val_accuracy: 0.7341\n",
      "Epoch 110/150\n",
      "57/57 [==============================] - 17s 299ms/step - loss: 0.7802 - accuracy: 0.8260 - val_loss: 1.0188 - val_accuracy: 0.7597\n",
      "Epoch 111/150\n",
      "57/57 [==============================] - 17s 296ms/step - loss: 0.8178 - accuracy: 0.8152 - val_loss: 1.1134 - val_accuracy: 0.7197\n",
      "Epoch 112/150\n",
      "57/57 [==============================] - 17s 295ms/step - loss: 0.7980 - accuracy: 0.8347 - val_loss: 0.9819 - val_accuracy: 0.7697\n",
      "Epoch 113/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 17s 294ms/step - loss: 0.8918 - accuracy: 0.7867 - val_loss: 0.8888 - val_accuracy: 0.8042\n",
      "Epoch 114/150\n",
      "57/57 [==============================] - 17s 298ms/step - loss: 0.8108 - accuracy: 0.8115 - val_loss: 0.8885 - val_accuracy: 0.8009\n",
      "Epoch 115/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 0.8341 - accuracy: 0.8032 - val_loss: 0.8763 - val_accuracy: 0.8087\n",
      "Epoch 116/150\n",
      "57/57 [==============================] - 16s 280ms/step - loss: 0.7357 - accuracy: 0.8408 - val_loss: 0.8718 - val_accuracy: 0.8087\n",
      "Epoch 117/150\n",
      "57/57 [==============================] - 16s 281ms/step - loss: 0.7703 - accuracy: 0.8370 - val_loss: 0.8143 - val_accuracy: 0.8209\n",
      "Epoch 118/150\n",
      "57/57 [==============================] - 16s 280ms/step - loss: 0.7580 - accuracy: 0.8397 - val_loss: 0.9890 - val_accuracy: 0.7686\n",
      "Epoch 119/150\n",
      "57/57 [==============================] - 16s 282ms/step - loss: 0.7422 - accuracy: 0.8466 - val_loss: 0.9624 - val_accuracy: 0.7675\n",
      "Epoch 120/150\n",
      "57/57 [==============================] - 16s 281ms/step - loss: 0.7838 - accuracy: 0.8147 - val_loss: 0.8887 - val_accuracy: 0.8020\n",
      "Epoch 121/150\n",
      "57/57 [==============================] - 16s 277ms/step - loss: 0.7591 - accuracy: 0.8290 - val_loss: 0.9137 - val_accuracy: 0.8042\n",
      "Epoch 122/150\n",
      "57/57 [==============================] - 16s 278ms/step - loss: 0.7297 - accuracy: 0.8365 - val_loss: 0.9175 - val_accuracy: 0.7909\n",
      "Epoch 123/150\n",
      "57/57 [==============================] - 16s 280ms/step - loss: 0.7440 - accuracy: 0.8297 - val_loss: 0.9705 - val_accuracy: 0.7831\n",
      "Epoch 124/150\n",
      "57/57 [==============================] - 16s 280ms/step - loss: 0.7224 - accuracy: 0.8458 - val_loss: 0.9430 - val_accuracy: 0.7875\n",
      "Epoch 125/150\n",
      "57/57 [==============================] - 16s 283ms/step - loss: 0.7589 - accuracy: 0.8258 - val_loss: 0.9967 - val_accuracy: 0.7542\n",
      "Epoch 126/150\n",
      "57/57 [==============================] - 16s 281ms/step - loss: 0.7273 - accuracy: 0.8464 - val_loss: 0.9535 - val_accuracy: 0.7753\n",
      "Epoch 127/150\n",
      "57/57 [==============================] - 16s 282ms/step - loss: 0.7624 - accuracy: 0.8346 - val_loss: 0.8696 - val_accuracy: 0.8031\n",
      "Epoch 128/150\n",
      "57/57 [==============================] - 16s 281ms/step - loss: 0.7134 - accuracy: 0.8556 - val_loss: 0.9888 - val_accuracy: 0.7564\n",
      "Epoch 129/150\n",
      "57/57 [==============================] - 16s 285ms/step - loss: 0.7132 - accuracy: 0.8447 - val_loss: 0.8742 - val_accuracy: 0.7987\n",
      "Epoch 130/150\n",
      "57/57 [==============================] - 16s 281ms/step - loss: 0.6924 - accuracy: 0.8550 - val_loss: 0.8348 - val_accuracy: 0.8120\n",
      "Epoch 131/150\n",
      "57/57 [==============================] - 16s 280ms/step - loss: 0.6953 - accuracy: 0.8564 - val_loss: 0.8503 - val_accuracy: 0.8142\n",
      "Epoch 132/150\n",
      "57/57 [==============================] - 16s 278ms/step - loss: 0.6935 - accuracy: 0.8583 - val_loss: 0.9690 - val_accuracy: 0.7653\n",
      "Epoch 133/150\n",
      "57/57 [==============================] - 16s 281ms/step - loss: 0.6941 - accuracy: 0.8410 - val_loss: 0.8549 - val_accuracy: 0.8176\n",
      "Epoch 134/150\n",
      "57/57 [==============================] - 17s 293ms/step - loss: 0.6948 - accuracy: 0.8395 - val_loss: 0.9977 - val_accuracy: 0.7653\n",
      "Epoch 135/150\n",
      "57/57 [==============================] - 16s 284ms/step - loss: 0.6944 - accuracy: 0.8553 - val_loss: 0.8420 - val_accuracy: 0.8087\n",
      "Epoch 136/150\n",
      "57/57 [==============================] - 16s 281ms/step - loss: 0.7182 - accuracy: 0.8357 - val_loss: 0.8926 - val_accuracy: 0.8076\n",
      "Epoch 137/150\n",
      "57/57 [==============================] - 16s 278ms/step - loss: 0.6918 - accuracy: 0.8539 - val_loss: 0.7756 - val_accuracy: 0.8320\n",
      "Epoch 138/150\n",
      "57/57 [==============================] - 16s 280ms/step - loss: 0.7078 - accuracy: 0.8532 - val_loss: 0.8955 - val_accuracy: 0.8076\n",
      "Epoch 139/150\n",
      "57/57 [==============================] - 16s 282ms/step - loss: 0.6943 - accuracy: 0.8544 - val_loss: 0.9023 - val_accuracy: 0.7931\n",
      "Epoch 140/150\n",
      "57/57 [==============================] - 16s 285ms/step - loss: 0.6625 - accuracy: 0.8659 - val_loss: 0.7892 - val_accuracy: 0.8276\n",
      "Epoch 141/150\n",
      "57/57 [==============================] - 16s 281ms/step - loss: 0.6839 - accuracy: 0.8451 - val_loss: 0.9631 - val_accuracy: 0.7920\n",
      "Epoch 142/150\n",
      "57/57 [==============================] - 16s 283ms/step - loss: 0.6958 - accuracy: 0.8537 - val_loss: 0.8886 - val_accuracy: 0.7998\n",
      "Epoch 143/150\n",
      "57/57 [==============================] - 16s 282ms/step - loss: 0.6726 - accuracy: 0.8672 - val_loss: 0.8430 - val_accuracy: 0.8053\n",
      "Epoch 144/150\n",
      "57/57 [==============================] - 16s 281ms/step - loss: 0.6822 - accuracy: 0.8475 - val_loss: 0.8849 - val_accuracy: 0.7875\n",
      "Epoch 145/150\n",
      "57/57 [==============================] - 16s 278ms/step - loss: 0.6679 - accuracy: 0.8431 - val_loss: 0.9708 - val_accuracy: 0.7775\n",
      "Epoch 146/150\n",
      "57/57 [==============================] - 16s 283ms/step - loss: 0.6661 - accuracy: 0.8564 - val_loss: 0.8188 - val_accuracy: 0.8120\n",
      "Epoch 147/150\n",
      "57/57 [==============================] - 16s 283ms/step - loss: 0.6278 - accuracy: 0.8692 - val_loss: 0.8544 - val_accuracy: 0.8042\n",
      "Epoch 148/150\n",
      "57/57 [==============================] - 16s 281ms/step - loss: 0.6562 - accuracy: 0.8625 - val_loss: 0.8905 - val_accuracy: 0.8020\n",
      "Epoch 149/150\n",
      "57/57 [==============================] - 16s 286ms/step - loss: 0.6580 - accuracy: 0.8535 - val_loss: 0.7683 - val_accuracy: 0.8409\n",
      "Epoch 150/150\n",
      "57/57 [==============================] - 16s 282ms/step - loss: 0.6115 - accuracy: 0.8773 - val_loss: 0.8415 - val_accuracy: 0.8187\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "          y_train, \n",
    "          validation_data = (X_validation, y_validation), \n",
    "          batch_size = 64, \n",
    "          epochs = 150,\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 20ms/step - loss: 0.7870 - accuracy: 0.8244 0s - loss: 0.7850 - accuracy: 0.\n"
     ]
    }
   ],
   "source": [
    "test_error, test_accuracy = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, axs = plt.subplots(2)\n",
    "\n",
    "    # create accuracy subplot\n",
    "    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n",
    "    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n",
    "    axs[0].set_ylabel(\"Accuracy\")\n",
    "    axs[0].legend(loc=\"lower right\")\n",
    "    axs[0].set_title(\"Accuracy Eval\")\n",
    "\n",
    "    # create error subplot\n",
    "    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n",
    "    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n",
    "    axs[1].set_ylabel(\"Error\")\n",
    "    axs[1].set_xlabel(\"Epoch\")\n",
    "    axs[1].legend(loc=\"upper right\")\n",
    "    axs[1].set_title(\"Error Eval\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-a8489d1127d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-90-f240aaf98434>\u001b[0m in \u001b[0;36mplot_history\u001b[1;34m(history)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# create accuracy subplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"test accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5138\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5139\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5141\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'history'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X_prediction, y_prediction):\n",
    "    \n",
    "    X_temp = X[np.newaxis, ...]\n",
    "    \n",
    "    # Plot predictions to a 2D Array\n",
    "    predictions = model.predict(X_temp)\n",
    "    \n",
    "    predicted_index = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    print(f'Target: {y}, Predicted label: {predicted_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prediction = X_test[200]\n",
    "y_prediction = y_test[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 9, Predicted label: [9]\n"
     ]
    }
   ],
   "source": [
    "predict(model, X_prediction, y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/cnn_model_6_segs_per_track.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
